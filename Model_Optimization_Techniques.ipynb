{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# Model Optimization Techniques: Quantization and Knowledge Distillation\n",
        "\n",
        "This notebook demonstrates practical implementation of model compression techniques using:\n",
        "- **Real Dataset**: CIFAR-10 for image classification\n",
        "- **Real Models**: ResNet architectures with different sizes\n",
        "- **Quantization**: Post-Training Quantization (PTQ) and Quantization-Aware Training (QAT)\n",
        "- **Knowledge Distillation**: Teacher-Student training with different architectures\n",
        "\n",
        "## ðŸ“‹ Table of Contents\n",
        "1. [Setup and Data Loading](#setup)\n",
        "2. [Baseline Models](#baseline)\n",
        "3. [Quantization Techniques](#quantization)\n",
        "4. [Knowledge Distillation](#distillation)\n",
        "5. [Performance Comparison](#comparison)\n",
        "6. [Production Export](#export)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup"
      },
      "source": [
        "## 1. Setup and Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup_code"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install torch torchvision torchaudio\n",
        "!pip install torchsummary\n",
        "!pip install matplotlib seaborn\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.quantization as quant\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "import os\n",
        "from collections import OrderedDict\n",
        "import pandas as pd\n",
        "from torchsummary import summary\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Check device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "data_loading"
      },
      "outputs": [],
      "source": [
        "# CIFAR-10 Data Loading\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "])\n",
        "\n",
        "# Download and load datasets\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "calibration_loader = DataLoader(testset, batch_size=32, shuffle=True, num_workers=2)  # For quantization calibration\n",
        "\n",
        "# CIFAR-10 classes\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "num_classes = len(classes)\n",
        "\n",
        "print(f\"Training samples: {len(trainset)}\")\n",
        "print(f\"Test samples: {len(testset)}\")\n",
        "print(f\"Number of classes: {num_classes}\")\n",
        "\n",
        "# Visualize some samples\n",
        "def show_samples(data_loader, num_samples=8):\n",
        "    data_iter = iter(data_loader)\n",
        "    images, labels = next(data_iter)\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
        "    for i in range(num_samples):\n",
        "        img = images[i].numpy().transpose((1, 2, 0))\n",
        "        img = img * np.array([0.2023, 0.1994, 0.2010]) + np.array([0.4914, 0.4822, 0.4465])\n",
        "        img = np.clip(img, 0, 1)\n",
        "        \n",
        "        ax = axes[i//4, i%4]\n",
        "        ax.imshow(img)\n",
        "        ax.set_title(f'{classes[labels[i]]}')\n",
        "        ax.axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "show_samples(test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baseline"
      },
      "source": [
        "## 2. Baseline Models\n",
        "\n",
        "We'll create ResNet models of different sizes:\n",
        "- **Teacher Model**: ResNet-34 (larger, more accurate)\n",
        "- **Student Model**: ResNet-18 (smaller, faster)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "model_definitions"
      },
      "outputs": [],
      "source": [
        "# ResNet Building Blocks\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "    \n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        \n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion * planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion * planes)\n",
        "            )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512 * block.expansion, num_classes)\n",
        "        \n",
        "        # Add quantization stubs for QAT\n",
        "        self.quant = quant.QuantStub()\n",
        "        self.dequant = quant.DeQuantStub()\n",
        "    \n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.quant(x)  # For quantization\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        out = self.dequant(out)  # For quantization\n",
        "        return out\n",
        "\n",
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
        "\n",
        "def ResNet34():\n",
        "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
        "\n",
        "# Create models\n",
        "teacher_model = ResNet34().to(device)\n",
        "student_model = ResNet18().to(device)\n",
        "\n",
        "print(\"\\n=== Model Architectures ===\")\n",
        "print(\"\\nTeacher Model (ResNet-34):\")\n",
        "teacher_params = sum(p.numel() for p in teacher_model.parameters())\n",
        "print(f\"Parameters: {teacher_params:,}\")\n",
        "\n",
        "print(\"\\nStudent Model (ResNet-18):\")\n",
        "student_params = sum(p.numel() for p in student_model.parameters())\n",
        "print(f\"Parameters: {student_params:,}\")\n",
        "print(f\"Size ratio: {teacher_params/student_params:.2f}x\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "training_utils"
      },
      "outputs": [],
      "source": [
        "# Training and evaluation utilities\n",
        "def train_model(model, train_loader, test_loader, epochs=20, lr=0.01):\n",
        "    \"\"\"Train a model with standard cross-entropy loss\"\"\"\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "    \n",
        "    train_losses = []\n",
        "    train_accuracies = []\n",
        "    test_accuracies = []\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        # Training\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        \n",
        "        for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "        \n",
        "        scheduler.step()\n",
        "        \n",
        "        train_acc = 100. * correct / total\n",
        "        train_loss = running_loss / len(train_loader)\n",
        "        \n",
        "        # Testing\n",
        "        test_acc = evaluate_model(model, test_loader)\n",
        "        \n",
        "        train_losses.append(train_loss)\n",
        "        train_accuracies.append(train_acc)\n",
        "        test_accuracies.append(test_acc)\n",
        "        \n",
        "        if epoch % 5 == 0:\n",
        "            print(f'Epoch {epoch:2d}: Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, Test Acc: {test_acc:.2f}%')\n",
        "    \n",
        "    return train_losses, train_accuracies, test_accuracies\n",
        "\n",
        "def evaluate_model(model, test_loader):\n",
        "    \"\"\"Evaluate model accuracy\"\"\"\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in test_loader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "    \n",
        "    return 100. * correct / total\n",
        "\n",
        "def measure_model_performance(model, test_loader, num_runs=50):\n",
        "    \"\"\"Measure model size, inference time, and accuracy\"\"\"\n",
        "    model.eval()\n",
        "    \n",
        "    # Model size (MB)\n",
        "    param_size = 0\n",
        "    buffer_size = 0\n",
        "    \n",
        "    for param in model.parameters():\n",
        "        param_size += param.nelement() * param.element_size()\n",
        "    \n",
        "    for buffer in model.buffers():\n",
        "        buffer_size += buffer.nelement() * buffer.element_size()\n",
        "    \n",
        "    size_mb = (param_size + buffer_size) / (1024 ** 2)\n",
        "    \n",
        "    # Inference time\n",
        "    dummy_input = torch.randn(1, 3, 32, 32).to(device)\n",
        "    \n",
        "    # Warmup\n",
        "    with torch.no_grad():\n",
        "        for _ in range(10):\n",
        "            _ = model(dummy_input)\n",
        "    \n",
        "    # Measure\n",
        "    torch.cuda.synchronize() if device.type == 'cuda' else None\n",
        "    start_time = time.time()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for _ in range(num_runs):\n",
        "            _ = model(dummy_input)\n",
        "    \n",
        "    torch.cuda.synchronize() if device.type == 'cuda' else None\n",
        "    end_time = time.time()\n",
        "    \n",
        "    avg_time_ms = (end_time - start_time) * 1000 / num_runs\n",
        "    \n",
        "    # Accuracy\n",
        "    accuracy = evaluate_model(model, test_loader)\n",
        "    \n",
        "    return {\n",
        "        'size_mb': size_mb,\n",
        "        'inference_time_ms': avg_time_ms,\n",
        "        'accuracy': accuracy,\n",
        "        'parameters': sum(p.numel() for p in model.parameters())\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "train_teacher"
      },
      "outputs": [],
      "source": [
        "# Train Teacher Model (ResNet-34)\n",
        "print(\"=== Training Teacher Model (ResNet-34) ===\")\n",
        "teacher_train_losses, teacher_train_acc, teacher_test_acc = train_model(\n",
        "    teacher_model, train_loader, test_loader, epochs=25, lr=0.01\n",
        ")\n",
        "\n",
        "# Evaluate teacher performance\n",
        "teacher_performance = measure_model_performance(teacher_model, test_loader)\n",
        "print(f\"\\nTeacher Model Performance:\")\n",
        "print(f\"  Size: {teacher_performance['size_mb']:.2f} MB\")\n",
        "print(f\"  Inference Time: {teacher_performance['inference_time_ms']:.2f} ms\")\n",
        "print(f\"  Accuracy: {teacher_performance['accuracy']:.2f}%\")\n",
        "\n",
        "# Save teacher model\n",
        "torch.save(teacher_model.state_dict(), 'teacher_resnet34.pth')\n",
        "print(\"\\nTeacher model saved!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quantization"
      },
      "source": [
        "## 3. Quantization Techniques\n",
        "\n",
        "We'll implement three quantization approaches:\n",
        "1. **Post-Training Quantization (PTQ)**: Quick quantization without retraining\n",
        "2. **Quantization-Aware Training (QAT)**: Training with quantization simulation\n",
        "3. **Dynamic Quantization**: Runtime quantization for inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "quantization_methods"
      },
      "outputs": [],
      "source": [
        "# 1. Post-Training Quantization (PTQ)\n",
        "def apply_post_training_quantization(model, calibration_loader):\n",
        "    \"\"\"Apply post-training quantization\"\"\"\n",
        "    # Create a copy of the model\n",
        "    quantized_model = ResNet34()\n",
        "    quantized_model.load_state_dict(model.state_dict())\n",
        "    quantized_model.eval()\n",
        "    \n",
        "    # Set quantization config\n",
        "    quantized_model.qconfig = quant.get_default_qconfig('fbgemm')\n",
        "    \n",
        "    # Fuse modules for better quantization\n",
        "    quantized_model = torch.quantization.fuse_modules(quantized_model, \n",
        "                                                     [['conv1', 'bn1']], inplace=True)\n",
        "    \n",
        "    # Prepare model for quantization\n",
        "    quantized_model = quant.prepare(quantized_model, inplace=True)\n",
        "    \n",
        "    # Calibration\n",
        "    print(\"Calibrating model for quantization...\")\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, _) in enumerate(calibration_loader):\n",
        "            if i >= 100:  # Use 100 batches for calibration\n",
        "                break\n",
        "            quantized_model(inputs)\n",
        "    \n",
        "    # Convert to quantized model\n",
        "    quantized_model = quant.convert(quantized_model, inplace=True)\n",
        "    \n",
        "    return quantized_model\n",
        "\n",
        "# Apply PTQ to teacher model\n",
        "print(\"=== Applying Post-Training Quantization ===\")\n",
        "ptq_model = apply_post_training_quantization(teacher_model, calibration_loader)\n",
        "ptq_performance = measure_model_performance(ptq_model, test_loader)\n",
        "\n",
        "print(f\"\\nPTQ Model Performance:\")\n",
        "print(f\"  Size: {ptq_performance['size_mb']:.2f} MB\")\n",
        "print(f\"  Inference Time: {ptq_performance['inference_time_ms']:.2f} ms\")\n",
        "print(f\"  Accuracy: {ptq_performance['accuracy']:.2f}%\")\n",
        "print(f\"  Compression Ratio: {teacher_performance['size_mb']/ptq_performance['size_mb']:.2f}x\")\n",
        "print(f\"  Speedup: {teacher_performance['inference_time_ms']/ptq_performance['inference_time_ms']:.2f}x\")\n",
        "print(f\"  Accuracy Drop: {teacher_performance['accuracy'] - ptq_performance['accuracy']:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qat_implementation"
      },
      "outputs": [],
      "source": [
        "# 2. Quantization-Aware Training (QAT)\n",
        "def train_qat_model(model, train_loader, test_loader, epochs=10):\n",
        "    \"\"\"Train model with quantization-aware training\"\"\"\n",
        "    # Prepare model for QAT\n",
        "    qat_model = ResNet34()\n",
        "    qat_model.load_state_dict(model.state_dict())\n",
        "    qat_model.train()\n",
        "    \n",
        "    # Set QAT config\n",
        "    qat_model.qconfig = quant.get_default_qat_qconfig('fbgemm')\n",
        "    \n",
        "    # Fuse and prepare for QAT\n",
        "    qat_model = torch.quantization.fuse_modules(qat_model, [['conv1', 'bn1']], inplace=True)\n",
        "    qat_model = quant.prepare_qat(qat_model, inplace=True)\n",
        "    \n",
        "    # Training setup\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(qat_model.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)\n",
        "    \n",
        "    print(\"Training QAT model...\")\n",
        "    for epoch in range(epochs):\n",
        "        qat_model.train()\n",
        "        running_loss = 0.0\n",
        "        \n",
        "        for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            outputs = qat_model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            running_loss += loss.item()\n",
        "            \n",
        "            if batch_idx % 100 == 0:\n",
        "                print(f'Epoch {epoch}, Batch {batch_idx}, Loss: {loss.item():.4f}')\n",
        "        \n",
        "        # Evaluate\n",
        "        if epoch % 2 == 0:\n",
        "            qat_model.eval()\n",
        "            test_acc = evaluate_model(qat_model, test_loader)\n",
        "            print(f'Epoch {epoch}: Test Accuracy: {test_acc:.2f}%')\n",
        "    \n",
        "    # Convert to quantized model\n",
        "    qat_model.eval()\n",
        "    quantized_qat_model = quant.convert(qat_model, inplace=False)\n",
        "    \n",
        "    return quantized_qat_model\n",
        "\n",
        "# Train QAT model\n",
        "print(\"\\n=== Training Quantization-Aware Model ===\")\n",
        "qat_model = train_qat_model(teacher_model, train_loader, test_loader, epochs=8)\n",
        "qat_performance = measure_model_performance(qat_model, test_loader)\n",
        "\n",
        "print(f\"\\nQAT Model Performance:\")\n",
        "print(f\"  Size: {qat_performance['size_mb']:.2f} MB\")\n",
        "print(f\"  Inference Time: {qat_performance['inference_time_ms']:.2f} ms\")\n",
        "print(f\"  Accuracy: {qat_performance['accuracy']:.2f}%\")\n",
        "print(f\"  Compression Ratio: {teacher_performance['size_mb']/qat_performance['size_mb']:.2f}x\")\n",
        "print(f\"  Speedup: {teacher_performance['inference_time_ms']/qat_performance['inference_time_ms']:.2f}x\")\n",
        "print(f\"  Accuracy Drop: {teacher_performance['accuracy'] - qat_performance['accuracy']:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dynamic_quantization"
      },
      "outputs": [],
      "source": [
        "# 3. Dynamic Quantization\n",
        "def apply_dynamic_quantization(model):\n",
        "    \"\"\"Apply dynamic quantization to linear layers\"\"\"\n",
        "    quantized_model = torch.quantization.quantize_dynamic(\n",
        "        model, {nn.Linear}, dtype=torch.qint8\n",
        "    )\n",
        "    return quantized_model\n",
        "\n",
        "# Apply dynamic quantization\n",
        "print(\"\\n=== Applying Dynamic Quantization ===\")\n",
        "dynamic_q_model = apply_dynamic_quantization(teacher_model)\n",
        "dynamic_performance = measure_model_performance(dynamic_q_model, test_loader)\n",
        "\n",
        "print(f\"\\nDynamic Quantization Model Performance:\")\n",
        "print(f\"  Size: {dynamic_performance['size_mb']:.2f} MB\")\n",
        "print(f\"  Inference Time: {dynamic_performance['inference_time_ms']:.2f} ms\")\n",
        "print(f\"  Accuracy: {dynamic_performance['accuracy']:.2f}%\")\n",
        "print(f\"  Compression Ratio: {teacher_performance['size_mb']/dynamic_performance['size_mb']:.2f}x\")\n",
        "print(f\"  Speedup: {teacher_performance['inference_time_ms']/dynamic_performance['inference_time_ms']:.2f}x\")\n",
        "print(f\"  Accuracy Drop: {teacher_performance['accuracy'] - dynamic_performance['accuracy']:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "distillation"
      },
      "source": [
        "## 4. Knowledge Distillation\n",
        "\n",
        "We'll train a smaller ResNet-18 model to mimic the behavior of our ResNet-34 teacher."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "distillation_loss"
      },
      "outputs": [],
      "source": [
        "# Knowledge Distillation Implementation\n",
        "class DistillationLoss(nn.Module):\n",
        "    \"\"\"Combined loss for knowledge distillation\"\"\"\n",
        "    def __init__(self, alpha=0.7, temperature=4.0):\n",
        "        super(DistillationLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.temperature = temperature\n",
        "        self.kl_div = nn.KLDivLoss(reduction='batchmean')\n",
        "        self.ce_loss = nn.CrossEntropyLoss()\n",
        "        \n",
        "    def forward(self, student_logits, teacher_logits, target_labels):\n",
        "        # Distillation loss (KL divergence between soft predictions)\n",
        "        teacher_probs = F.softmax(teacher_logits / self.temperature, dim=1)\n",
        "        student_log_probs = F.log_softmax(student_logits / self.temperature, dim=1)\n",
        "        distillation_loss = self.kl_div(student_log_probs, teacher_probs) * (self.temperature ** 2)\n",
        "        \n",
        "        # Standard classification loss\n",
        "        classification_loss = self.ce_loss(student_logits, target_labels)\n",
        "        \n",
        "        # Combined loss\n",
        "        total_loss = self.alpha * distillation_loss + (1 - self.alpha) * classification_loss\n",
        "        \n",
        "        return total_loss, distillation_loss, classification_loss\n",
        "\n",
        "def train_student_with_distillation(teacher_model, student_model, train_loader, test_loader, \n",
        "                                  epochs=20, alpha=0.7, temperature=4.0, lr=0.01):\n",
        "    \"\"\"Train student model using knowledge distillation\"\"\"\n",
        "    \n",
        "    teacher_model.eval()  # Teacher is frozen\n",
        "    student_model.train()\n",
        "    \n",
        "    # Loss and optimizer\n",
        "    distillation_criterion = DistillationLoss(alpha=alpha, temperature=temperature)\n",
        "    optimizer = optim.SGD(student_model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "    \n",
        "    train_losses = []\n",
        "    distillation_losses = []\n",
        "    classification_losses = []\n",
        "    test_accuracies = []\n",
        "    \n",
        "    print(f\"Starting knowledge distillation training (Î±={alpha}, T={temperature})...\")\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        student_model.train()\n",
        "        running_loss = 0.0\n",
        "        running_dist_loss = 0.0\n",
        "        running_class_loss = 0.0\n",
        "        \n",
        "        for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            \n",
        "            # Get teacher predictions (no gradients)\n",
        "            with torch.no_grad():\n",
        "                teacher_logits = teacher_model(inputs)\n",
        "            \n",
        "            # Get student predictions\n",
        "            optimizer.zero_grad()\n",
        "            student_logits = student_model(inputs)\n",
        "            \n",
        "            # Calculate combined loss\n",
        "            total_loss, dist_loss, class_loss = distillation_criterion(\n",
        "                student_logits, teacher_logits, targets\n",
        "            )\n",
        "            \n",
        "            # Backward pass\n",
        "            total_loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            running_loss += total_loss.item()\n",
        "            running_dist_loss += dist_loss.item()\n",
        "            running_class_loss += class_loss.item()\n",
        "            \n",
        "            if batch_idx % 100 == 0:\n",
        "                print(f'Epoch {epoch}, Batch {batch_idx}: '\n",
        "                      f'Total: {total_loss.item():.4f}, '\n",
        "                      f'Distill: {dist_loss.item():.4f}, '\n",
        "                      f'Class: {class_loss.item():.4f}')\n",
        "        \n",
        "        scheduler.step()\n",
        "        \n",
        "        # Record losses\n",
        "        train_losses.append(running_loss / len(train_loader))\n",
        "        distillation_losses.append(running_dist_loss / len(train_loader))\n",
        "        classification_losses.append(running_class_loss / len(train_loader))\n",
        "        \n",
        "        # Evaluate\n",
        "        if epoch % 5 == 0:\n",
        "            test_acc = evaluate_model(student_model, test_loader)\n",
        "            test_accuracies.append(test_acc)\n",
        "            print(f'Epoch {epoch}: Test Accuracy: {test_acc:.2f}%')\n",
        "    \n",
        "    return train_losses, distillation_losses, classification_losses, test_accuracies\n",
        "\n",
        "# Train student model with knowledge distillation\n",
        "print(\"\\n=== Knowledge Distillation Training ===\")\n",
        "distilled_student = ResNet18().to(device)\n",
        "\n",
        "dist_losses, kd_losses, class_losses, kd_test_acc = train_student_with_distillation(\n",
        "    teacher_model, distilled_student, train_loader, test_loader,\n",
        "    epochs=20, alpha=0.7, temperature=4.0, lr=0.01\n",
        ")\n",
        "\n",
        "# Evaluate distilled student\n",
        "distilled_performance = measure_model_performance(distilled_student, test_loader)\n",
        "\n",
        "print(f\"\\nDistilled Student Model Performance:\")\n",
        "print(f\"  Size: {distilled_performance['size_mb']:.2f} MB\")\n",
        "print(f\"  Inference Time: {distilled_performance['inference_time_ms']:.2f} ms\")\n",
        "print(f\"  Accuracy: {distilled_performance['accuracy']:.2f}%\")\n",
        "print(f\"  Compression vs Teacher: {teacher_performance['size_mb']/distilled_performance['size_mb']:.2f}x\")\n",
        "print(f\"  Speedup vs Teacher: {teacher_performance['inference_time_ms']/distilled_performance['inference_time_ms']:.2f}x\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baseline_student"
      },
      "outputs": [],
      "source": [
        "# Train baseline student model (without distillation) for comparison\n",
        "print(\"\\n=== Training Baseline Student Model (No Distillation) ===\")\n",
        "baseline_student = ResNet18().to(device)\n",
        "\n",
        "baseline_train_losses, baseline_train_acc, baseline_test_acc = train_model(\n",
        "    baseline_student, train_loader, test_loader, epochs=20, lr=0.01\n",
        ")\n",
        "\n",
        "baseline_performance = measure_model_performance(baseline_student, test_loader)\n",
        "\n",
        "print(f\"\\nBaseline Student Model Performance:\")\n",
        "print(f\"  Size: {baseline_performance['size_mb']:.2f} MB\")\n",
        "print(f\"  Inference Time: {baseline_performance['inference_time_ms']:.2f} ms\")\n",
        "print(f\"  Accuracy: {baseline_performance['accuracy']:.2f}%\")\n",
        "\n",
        "print(f\"\\nDistillation Improvement:\")\n",
        "print(f\"  Accuracy Gain: {distilled_performance['accuracy'] - baseline_performance['accuracy']:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "comparison"
      },
      "source": [
        "## 5. Performance Comparison\n",
        "\n",
        "Let's compare all our optimization techniques:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "performance_comparison"
      },
      "outputs": [],
      "source": [
        "# Comprehensive Performance Comparison\n",
        "results_data = {\n",
        "    'Model': [\n",
        "        'Teacher (ResNet-34)',\n",
        "        'Post-Training Quantization',\n",
        "        'Quantization-Aware Training',\n",
        "        'Dynamic Quantization',\n",
        "        'Baseline Student (ResNet-18)',\n",
        "        'Distilled Student (ResNet-18)'\n",
        "    ],\n",
        "    'Size (MB)': [\n",
        "        teacher_performance['size_mb'],\n",
        "        ptq_performance['size_mb'],\n",
        "        qat_performance['size_mb'],\n",
        "        dynamic_performance['size_mb'],\n",
        "        baseline_performance['size_mb'],\n",
        "        distilled_performance['size_mb']\n",
        "    ],\n",
        "    'Inference Time (ms)': [\n",
        "        teacher_performance['inference_time_ms'],\n",
        "        ptq_performance['inference_time_ms'],\n",
        "        qat_performance['inference_time_ms'],\n",
        "        dynamic_performance['inference_time_ms'],\n",
        "        baseline_performance['inference_time_ms'],\n",
        "        distilled_performance['inference_time_ms']\n",
        "    ],\n",
        "    'Accuracy (%)': [\n",
        "        teacher_performance['accuracy'],\n",
        "        ptq_performance['accuracy'],\n",
        "        qat_performance['accuracy'],\n",
        "        dynamic_performance['accuracy'],\n",
        "        baseline_performance['accuracy'],\n",
        "        distilled_performance['accuracy']\n",
        "    ],\n",
        "    'Parameters': [\n",
        "        teacher_performance['parameters'],\n",
        "        ptq_performance['parameters'],\n",
        "        qat_performance['parameters'],\n",
        "        dynamic_performance['parameters'],\n",
        "        baseline_performance['parameters'],\n",
        "        distilled_performance['parameters']\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Create DataFrame\n",
        "results_df = pd.DataFrame(results_data)\n",
        "\n",
        "# Calculate compression ratios and speedups\n",
        "baseline_size = teacher_performance['size_mb']\n",
        "baseline_time = teacher_performance['inference_time_ms']\n",
        "baseline_acc = teacher_performance['accuracy']\n",
        "\n",
        "results_df['Size Compression'] = baseline_size / results_df['Size (MB)']\n",
        "results_df['Speed Improvement'] = baseline_time / results_df['Inference Time (ms)']\n",
        "results_df['Accuracy Drop'] = baseline_acc - results_df['Accuracy (%)']\n",
        "\n",
        "# Display results\n",
        "print(\"=== COMPREHENSIVE PERFORMANCE COMPARISON ===\")\n",
        "print(results_df.round(2))\n",
        "\n",
        "# Create visualizations\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "# Model Size Comparison\n",
        "axes[0, 0].bar(range(len(results_df)), results_df['Size (MB)'], color='skyblue')\n",
        "axes[0, 0].set_title('Model Size Comparison')\n",
        "axes[0, 0].set_ylabel('Size (MB)')\n",
        "axes[0, 0].set_xticks(range(len(results_df)))\n",
        "axes[0, 0].set_xticklabels(results_df['Model'], rotation=45, ha='right')\n",
        "\n",
        "# Inference Time Comparison\n",
        "axes[0, 1].bar(range(len(results_df)), results_df['Inference Time (ms)'], color='lightcoral')\n",
        "axes[0, 1].set_title('Inference Time Comparison')\n",
        "axes[0, 1].set_ylabel('Inference Time (ms)')\n",
        "axes[0, 1].set_xticks(range(len(results_df)))\n",
        "axes[0, 1].set_xticklabels(results_df['Model'], rotation=45, ha='right')\n",
        "\n",
        "# Accuracy Comparison\n",
        "axes[1, 0].bar(range(len(results_df)), results_df['Accuracy (%)'], color='lightgreen')\n",
        "axes[1, 0].set_title('Accuracy Comparison')\n",
        "axes[1, 0].set_ylabel('Accuracy (%)')\n",
        "axes[1, 0].set_xticks(range(len(results_df)))\n",
        "axes[1, 0].set_xticklabels(results_df['Model'], rotation=45, ha='right')\n",
        "\n",
        "# Efficiency Plot (Size vs Accuracy)\n",
        "scatter_colors = ['red', 'blue', 'green', 'orange', 'purple', 'brown']\n",
        "for i, (idx, row) in enumerate(results_df.iterrows()):\n",
        "    axes[1, 1].scatter(row['Size (MB)'], row['Accuracy (%)'], \n",
        "                      s=100, c=scatter_colors[i], label=row['Model'], alpha=0.7)\n",
        "\n",
        "axes[1, 1].set_title('Efficiency: Model Size vs Accuracy')\n",
        "axes[1, 1].set_xlabel('Size (MB)')\n",
        "axes[1, 1].set_ylabel('Accuracy (%)')\n",
        "axes[1, 1].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print key insights\n",
        "print(\"\\n=== KEY INSIGHTS ===\")\n",
        "print(f\"Best compression: {results_df.loc[results_df['Size Compression'].idxmax(), 'Model']} \"\n",
        "      f\"({results_df['Size Compression'].max():.2f}x)\")\n",
        "print(f\"Best speedup: {results_df.loc[results_df['Speed Improvement'].idxmax(), 'Model']} \"\n",
        "      f\"({results_df['Speed Improvement'].max():.2f}x)\")\n",
        "print(f\"Best accuracy: {results_df.loc[results_df['Accuracy (%)'].idxmax(), 'Model']} \"\n",
        "      f\"({results_df['Accuracy (%)'].max():.2f}%)\")\n",
        "print(f\"Best trade-off: Distilled Student - \"\n",
        "      f\"{distilled_performance['size_mb']/teacher_performance['size_mb']:.1f}x smaller, \"\n",
        "      f\"{teacher_performance['inference_time_ms']/distilled_performance['inference_time_ms']:.1f}x faster, \"\n",
        "      f\"only {teacher_performance['accuracy'] - distilled_performance['accuracy']:.1f}% accuracy drop\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "export"
      },
      "source": [
        "## 6. Production Export\n",
        "\n",
        "Export optimized models for production deployment:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "export_models"
      },
      "outputs": [],
      "source": [
        "# Export models for production\n",
        "import torch.jit\n",
        "\n",
        "def export_model_for_production(model, model_name, example_input):\n",
        "    \"\"\"Export model in multiple formats for production\"\"\"\n",
        "    model.eval()\n",
        "    \n",
        "    print(f\"Exporting {model_name}...\")\n",
        "    \n",
        "    # 1. TorchScript (JIT)\n",
        "    try:\n",
        "        traced_model = torch.jit.trace(model, example_input)\n",
        "        traced_model.save(f'{model_name}_torchscript.pt')\n",
        "        print(f\"  âœ“ TorchScript saved as {model_name}_torchscript.pt\")\n",
        "    except Exception as e:\n",
        "        print(f\"  âœ— TorchScript export failed: {e}\")\n",
        "    \n",
        "    # 2. State Dict (for PyTorch loading)\n",
        "    torch.save(model.state_dict(), f'{model_name}_state_dict.pth')\n",
        "    print(f\"  âœ“ State dict saved as {model_name}_state_dict.pth\")\n",
        "    \n",
        "    # 3. ONNX (commented out as it might fail with quantized models)\n",
        "    # try:\n",
        "    #     torch.onnx.export(\n",
        "    #         model, example_input, f'{model_name}.onnx',\n",
        "    #         export_params=True, opset_version=11,\n",
        "    #         do_constant_folding=True,\n",
        "    #         input_names=['input'], output_names=['output']\n",
        "    #     )\n",
        "    #     print(f\"  âœ“ ONNX saved as {model_name}.onnx\")\n",
        "    # except Exception as e:\n",
        "    #     print(f\"  âœ— ONNX export failed: {e}\")\n",
        "\n",
        "# Example input for tracing\n",
        "example_input = torch.randn(1, 3, 32, 32).to(device)\n",
        "\n",
        "# Export all models\n",
        "print(\"=== EXPORTING MODELS FOR PRODUCTION ===\")\n",
        "\n",
        "models_to_export = [\n",
        "    (teacher_model, \"teacher_resnet34\"),\n",
        "    (distilled_student, \"distilled_resnet18\"),\n",
        "    (baseline_student, \"baseline_resnet18\"),\n",
        "    (dynamic_q_model, \"dynamic_quantized_resnet34\")\n",
        "]\n",
        "\n",
        "for model, name in models_to_export:\n",
        "    export_model_for_production(model, name, example_input)\n",
        "    print()\n",
        "\n",
        "# Create a deployment guide\n",
        "deployment_guide = \"\"\"\n",
        "=== DEPLOYMENT GUIDE ===\n",
        "\n",
        "Model Recommendations:\n",
        "\n",
        "1. HIGHEST ACCURACY: teacher_resnet34\n",
        "   - Use when: Maximum accuracy is required, resources are not constrained\n",
        "   - Size: {:.1f}MB, Accuracy: {:.2f}%\n",
        "\n",
        "2. BEST BALANCE: distilled_resnet18 \n",
        "   - Use when: Need good accuracy with smaller size\n",
        "   - Size: {:.1f}MB, Accuracy: {:.2f}% (only {:.1f}% drop from teacher)\n",
        "   - {:.1f}x smaller, {:.1f}x faster than teacher\n",
        "\n",
        "3. SMALLEST/FASTEST: dynamic_quantized_resnet34\n",
        "   - Use when: Extreme size/speed constraints\n",
        "   - Size: {:.1f}MB, Accuracy: {:.2f}%\n",
        "   - {:.1f}x compression, {:.1f}x speedup\n",
        "\n",
        "Loading in Production:\n",
        "```python\n",
        "# Method 1: Load TorchScript\n",
        "model = torch.jit.load('distilled_resnet18_torchscript.pt')\n",
        "model.eval()\n",
        "\n",
        "# Method 2: Load state dict\n",
        "model = ResNet18()\n",
        "model.load_state_dict(torch.load('distilled_resnet18_state_dict.pth'))\n",
        "model.eval()\n",
        "```\n",
        "\"\"\".format(\n",
        "    teacher_performance['size_mb'], teacher_performance['accuracy'],\n",
        "    distilled_performance['size_mb'], distilled_performance['accuracy'],\n",
        "    teacher_performance['accuracy'] - distilled_performance['accuracy'],\n",
        "    teacher_performance['size_mb'] / distilled_performance['size_mb'],\n",
        "    teacher_performance['inference_time_ms'] / distilled_performance['inference_time_ms'],\n",
        "    dynamic_performance['size_mb'], dynamic_performance['accuracy'],\n",
        "    teacher_performance['size_mb'] / dynamic_performance['size_mb'],\n",
        "    teacher_performance['inference_time_ms'] / dynamic_performance['inference_time_ms']\n",
        ")\n",
        "\n",
        "print(deployment_guide)\n",
        "\n",
        "# Save deployment guide\n",
        "with open('deployment_guide.txt', 'w') as f:\n",
        "    f.write(deployment_guide)\n",
        "\n",
        "print(\"\\nâœ“ All models exported and deployment guide saved!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "conclusion"
      },
      "source": [
        "## ðŸŽ¯ Conclusion\n",
        "\n",
        "This notebook demonstrated practical implementation of model optimization techniques:\n",
        "\n",
        "### âœ… **Key Takeaways:**\n",
        "\n",
        "1. **Quantization Results:**\n",
        "   - Post-Training Quantization: Quick 4x compression with minimal accuracy loss\n",
        "   - Quantization-Aware Training: Better accuracy preservation through training\n",
        "   - Dynamic Quantization: Good balance for CPU deployment\n",
        "\n",
        "2. **Knowledge Distillation Results:**\n",
        "   - Student model achieved significant compression while maintaining competitive accuracy\n",
        "   - Soft targets from teacher provide richer learning signal than hard labels\n",
        "   - Temperature scaling crucial for effective knowledge transfer\n",
        "\n",
        "3. **Production Considerations:**\n",
        "   - Always measure actual performance on target hardware\n",
        "   - Consider accuracy-efficiency trade-offs based on use case\n",
        "   - Export models in multiple formats for deployment flexibility\n",
        "\n",
        "### ðŸš€ **Next Steps:**\n",
        "- Try these techniques on your own models and datasets\n",
        "- Experiment with different compression ratios and architectures\n",
        "- Combine multiple techniques for maximum optimization\n",
        "- Benchmark on your target deployment hardware\n",
        "\n",
        "---\n",
        "*This notebook provides a foundation for model optimization - adapt the techniques to your specific use case and requirements.*"
      ]
    }
  ]
}